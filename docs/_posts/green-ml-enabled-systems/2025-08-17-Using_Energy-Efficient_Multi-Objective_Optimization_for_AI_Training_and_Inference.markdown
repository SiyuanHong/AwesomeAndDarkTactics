---
layout: tactic

title:  "[Using Energy-Efficient Multi-Objective Optimization for AI Training and Inference]"
tags: algorithm-design machine-learning performance
t-sort: "Awesome Tactic"
t-type: "Architectural Tactic"
categories: green-ml-enabled-systems
t-description: "Applying a dynamic, phase-aware multi-objective optimization algorithm to AI model training and inference. It balances energy consumption and model accuracy by using gradient-based optimization techniques, Pareto front analysis, and real-time performance feedback. The system dynamically adjusts learning rate, quantization levels, and trade-off weights to minimize energy usage without degrading accuracy beyond an acceptable threshold"
t-participant: "AI engineers"
t-artifact: "AI models integrated within enterprise applications (e.g.,deep learning pipelines, inference services)"
t-context: "Large-scale enterprise environments where AI models are deployed for operational decision-making or automation, and where energy usage is a cost or sustainability concern"
t-feature: "Model training and inference phases with support for dynamic optimization (e.g., adjustable learning rates, quantization strategies, gradient sparsity)"
t-intent: "To reduce the overall energy consumption of AI systems while ensuring model performance remains within acceptable bounds"
t-targetQA: "Energy efficiency"
t-relatedQA: "Performance"
t-measuredimpact: "Energy consumption, Accuracy, Task execution time"
t-source: "S. Dash, Green AI: Enhancing Sustainability and Energy Efficiency in AI-Integrated Enterprise Systems, in IEEE Access, vol. 13, pp. 21216-21228, 2025"
t-source-doi: "https://doi.org/10.1109/ACCESS.2025.3532838."
---